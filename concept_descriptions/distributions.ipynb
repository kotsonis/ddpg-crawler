{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions\r\n",
    "This notebook serves two purposes:\r\n",
    "* Explain distributions in pytorch\r\n",
    "* Explain why we need distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.distributions import Normal, MultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.tensor(1.0)\r\n",
    "norm_dist = Normal(mean, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2979)\n"
     ]
    }
   ],
   "source": [
    "print(norm_dist.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packing many means is actualy interpreted as packing the mean and scale together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1837)\n"
     ]
    }
   ],
   "source": [
    "means = torch.tensor([1.0, 2.0])\r\n",
    "norm_dist = Normal(*means,1.0)\r\n",
    "print(norm_dist.sample())\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass a tensor with multiple means into a normal distribution, and a sample would provide a tensor with sampled values for each mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5203, 0.3677, 1.0054, 0.0198, 0.3305])\n"
     ]
    }
   ],
   "source": [
    "means = torch.tensor([0.5,0.2,0.7,0.3,0.4])\r\n",
    "norm_dist5 = Normal(means, 1.0)\r\n",
    "print (norm_dist5.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([5]), torch.Size([]))"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(norm_dist5.batch_shape, norm_dist5.event_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([]), torch.Size([5]))"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_var = MultivariateNormal(means,torch.eye(len(means)))\r\n",
    "(multi_var.batch_shape,multi_var.event_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.44347823 -1.4636948   0.2527554   0.45634598  0.65050125]]\n",
      "\n",
      " [[-0.0171302  -2.365741    0.62106913  0.8216393   0.6089853 ]]\n",
      "\n",
      " [[ 0.89379555 -0.630736    3.0626993   1.6567123   0.41341266]]]\n"
     ]
    }
   ],
   "source": [
    "sample = multi_var.sample((3,1))\r\n",
    "print(sample.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-6.5673],\n        [-8.1809],\n        [-8.7289]])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_var.log_prob(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.4003948  -0.19401081  0.69256896  0.03811589  0.59478474]]\n",
      "\n",
      " [[-0.0298236   0.46084344  0.47241724 -0.7908543   1.7463951 ]]\n",
      "\n",
      " [[ 1.3908324   1.7529848   0.35246193  1.328706    0.8006342 ]]]\n",
      "[[[0.49947804 0.19992974 0.7007838  0.2987778  0.400642  ]]\n",
      "\n",
      " [[0.50044644 0.20053618 0.70028925 0.3001508  0.39983553]]\n",
      "\n",
      " [[0.5004401  0.19892773 0.69843525 0.2995331  0.40091994]]]\n",
      "[0.5 0.2 0.7 0.3 0.4]\n",
      "tensor([29.9441])\n"
     ]
    }
   ],
   "source": [
    "multi_var = MultivariateNormal(means,torch.eye(len(means)))\r\n",
    "(multi_var.batch_shape,multi_var.event_shape)\r\n",
    "sample = multi_var.sample((3,1))\r\n",
    "print(sample.numpy())\r\n",
    "multi_var = MultivariateNormal(means,0.000001*torch.eye(len(means)))\r\n",
    "(multi_var.batch_shape,multi_var.event_shape)\r\n",
    "sample = multi_var.sample((3,1))\r\n",
    "print(sample.numpy())\r\n",
    "print(means.numpy())\r\n",
    "print(multi_var.log_prob(means.unsqueeze(0)))\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating multiple distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance per dimension : tensor([3., 3., 4., 5., 6.])\n",
      "covariance matrix :\n",
      " tensor([[[3., 0., 0., 0., 0.],\n",
      "         [0., 3., 0., 0., 0.],\n",
      "         [0., 0., 4., 0., 0.],\n",
      "         [0., 0., 0., 5., 0.],\n",
      "         [0., 0., 0., 0., 6.]],\n",
      "\n",
      "        [[2., 0., 0., 0., 0.],\n",
      "         [0., 2., 0., 0., 0.],\n",
      "         [0., 0., 3., 0., 0.],\n",
      "         [0., 0., 0., 4., 0.],\n",
      "         [0., 0., 0., 0., 5.]]])\n"
     ]
    }
   ],
   "source": [
    "type = torch.float\r\n",
    "\r\n",
    "cov_var = torch.full(size=(5,),fill_value=0.5, dtype=type)\r\n",
    "cov_var = torch.tensor([3,3,4,5,6], dtype=type)\r\n",
    "print(\"variance per dimension :\", cov_var)\r\n",
    "cov_mat = torch.stack((torch.diag(cov_var),torch.diag(cov_var-1.0)))\r\n",
    "print(\"covariance matrix :\\n\", cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0921,  1.3728, -0.3358,  1.4643, -1.0745],\n",
      "        [ 3.2573,  2.8846,  2.6515,  6.5360,  5.8733]])\n",
      "tensor([1.0064, 1.0090])\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "means = torch.tensor([[0.5, 0.2, 0.7, 0.3, 0.4],\r\n",
    "                     [3, 3, 4, 5, 6]],dtype=type)\r\n",
    "\r\n",
    "multi_var = MultivariateNormal(means,cov_mat)\r\n",
    "(multi_var.batch_shape, multi_var.event_shape)\r\n",
    "x = multi_var.sample()\r\n",
    "print(x)\r\n",
    "test = torch.tensor([[0.5, 0.2, 0.7, 0.3, 0.4],\r\n",
    "                     [3, 3, 4, 5, 6]],dtype=type)\r\n",
    "test_2 = test-1e-1\r\n",
    "a = multi_var.log_prob(test)\r\n",
    "b = multi_var.log_prob(test_2)\r\n",
    "c = torch.exp(a-b)\r\n",
    "print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-4.5947)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_var.log_prob(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the log probability that a specific tensor has in comparison to the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =tensor([0.2889, 3.4804, 4.2946, 3.0338, 5.3648]), log_prob = tensor([-1.1718, -2.0148, -1.7569, -1.3857, -0.9855])\n",
      "means=tensor([1., 2., 3., 4., 5.]),\n",
      "\t log_prob = tensor([-0.9189, -0.9189, -0.9189, -0.9189, -0.9189]),\n",
      "\t log_log = tensor([-0.0845, -0.0845, -0.0845, -0.0845, -0.0845])\n",
      "x=tensor([-0.0431,  1.3103,  2.6622,  4.3412,  5.4286])\n",
      "\tlog_prob = tensor([-1.4630, -1.1568, -0.9760, -0.9771, -1.0108])\n",
      "\t prob/mean prob = tensor([1.5920, 1.2588, 1.0621, 1.0633, 1.0999])\n",
      "x=tensor([1.3763, 2.5513, 4.6796, 2.7699, 5.2146])\n",
      "\tlog_prob = tensor([-0.9897, -1.0709, -2.3295, -1.6755, -0.9420])\n",
      "\t prob/mean prob = tensor([1.0770, 1.1654, 2.5350, 1.8233, 1.0251])\n",
      "x=tensor([1.6428, 1.7658, 3.4495, 4.2267, 5.3016])\n",
      "\tlog_prob = tensor([-1.1256, -0.9464, -1.0200, -0.9446, -0.9644])\n",
      "\t prob/mean prob = tensor([1.2248, 1.0299, 1.1100, 1.0280, 1.0495])\n",
      "x=tensor([0.6541, 2.1856, 2.1194, 3.7145, 5.9594])\n",
      "\tlog_prob = tensor([-0.9788, -0.9362, -1.3067, -0.9597, -1.3791])\n",
      "\t prob/mean prob = tensor([1.0651, 1.0187, 1.4220, 1.0444, 1.5008])\n",
      "x=tensor([1.1895, 1.7502, 3.0310, 3.0660, 4.0599])\n",
      "\tlog_prob = tensor([-0.9369, -0.9501, -0.9194, -1.3551, -1.3608])\n",
      "\t prob/mean prob = tensor([1.0195, 1.0340, 1.0005, 1.4747, 1.4809])\n"
     ]
    }
   ],
   "source": [
    "x = norm_dist5.sample()\r\n",
    "print(\"x ={}, log_prob = {}\".format(x,norm_dist5.log_prob(x)))\r\n",
    "print(\"means={},\\n\\t log_prob = {},\\n\\t log_log = {}\".format(means, norm_dist5.log_prob(means), torch.log(-norm_dist5.log_prob(means))))\r\n",
    "m_log_prob = norm_dist5.log_prob(means)\r\n",
    "for i in range(5):\r\n",
    "    x = norm_dist5.sample()\r\n",
    "    x_log_prb = norm_dist5.log_prob(x)\r\n",
    "    x_log_log = x_log_prb/m_log_prob\r\n",
    "    print(\"x={}\\n\\tlog_prob = {}\\n\\t prob/mean prob = {}\".format(x, x_log_prb, x_log_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to understand log_prob a bit better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy. meshgrid function is used to create a rectangular grid out of two given one-dimensional arrays representing the Cartesian indexing or Matrix indexing. Meshgrid function is somewhat inspired from MATLAB. ... meshgrid function returns two 2-Dimensional arrays representing the X and Y coordinates of all the points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sample across more than one action dimension therefore, we need the multi-variate Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-5f39ffc1cb5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmv_normal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0msamples_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0msamples_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "means = torch.tensor([0.0,0.0,0.0,-0.1,0.1])\r\n",
    "\r\n",
    "\r\n",
    "nums = 10000\r\n",
    "for cov_mat_mul in torch.arange(0.1,1.5,step=0.2):\r\n",
    "    mv_normal = MultivariateNormal(means,torch.eye(5)*cov_mat_mul)\r\n",
    "    samples= torch.zeros((nums,5))\r\n",
    "    for i in range(nums):\r\n",
    "        samples[i] = mv_normal.sample()\r\n",
    "        samples = torch.tensor(samples)\r\n",
    "    samples_mean = samples.mean(0)\r\n",
    "    samples_max, _ = samples.max(0)\r\n",
    "    samples_min, _ = samples.min(0)\r\n",
    "\r\n",
    "    print(\"multiplier: \",cov_mat_mul,\"\\nmean :\\t\", samples_mean,\"\\nmax\\t:\",samples_max,\"\\nmin\\t:\",samples_min)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting states to probabilities. What does the function from PPO utils do ??\r\n",
    "\r\n",
    "```python\r\n",
    "# convert states to probability, passing through the policy\r\n",
    "def states_to_prob(policy, states):\r\n",
    "    states = torch.stack(states)\r\n",
    "    policy_input = states.view(-1,*states.shape[-3:])\r\n",
    "    return policy(policy_input).view(states.shape[:-3])\r\n",
    "```\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states: \n",
      " (tensor([1, 1, 1, 1, 1, 1]), tensor([2, 2, 2, 2, 2, 2]), tensor([3, 3, 3, 3, 3, 3]))\n",
      "after stack: \n",
      " tensor([[1, 1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2, 2],\n",
      "        [3, 3, 3, 3, 3, 3]])\n",
      "torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "states = tuple((torch.tensor([1,1,1,1,1,1]),\r\n",
    "                torch.tensor([2,2,2,2,2,2]),\r\n",
    "                torch.tensor([3,3,3,3,3,3])))\r\n",
    "                      \r\n",
    "               \r\n",
    "print(\"states: \\n\", states)\r\n",
    "states = torch.stack(states)\r\n",
    "print(\"after stack: \\n\", states)\r\n",
    "print(states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the ```states.view(-1,*states.shape[-3:])``` operation just adds another dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 1, 1, 1, 1, 1],\n",
      "         [2, 2, 2, 2, 2, 2],\n",
      "         [3, 3, 3, 3, 3, 3]]])\n",
      "torch.Size([1, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "s_view = states.view(-1,*states.shape[-3:])\r\n",
    "print(s_view)\r\n",
    "print(s_view.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 1, 1, 1, 1, 1],\n",
      "         [2, 2, 2, 2, 2, 2],\n",
      "         [3, 3, 3, 3, 3, 3]]])\n",
      "torch.Size([1, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "s_view2 = states.unsqueeze(0)\r\n",
    "print(s_view2)\r\n",
    "print(s_view2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[True, True, True, True, True, True],\n",
      "         [True, True, True, True, True, True],\n",
      "         [True, True, True, True, True, True]]])\n"
     ]
    }
   ],
   "source": [
    "print(s_view == s_view2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2, 2]) tensor([[2, 2, 2, 2]])\n",
      "tensor([[2, 2, 2, 2],\n",
      "        [2, 2, 2, 2],\n",
      "        [2, 2, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "\r\n",
    "a = torch.tensor([2,2,2,2])\r\n",
    "b = a.unsqueeze(0)\r\n",
    "print(a,b)\r\n",
    "c = a.unsqueeze(0).repeat(3,1)\r\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.8088])\n",
      "tensor([-0.2258])\n",
      "tensor([0.7979])\n",
      "num:  tensor(0.)  log prob:  tensor([-18.2258])  prob:  tensor([1.2152e-08])\n",
      "num:  tensor(0.5000)  log prob:  tensor([-12.7258])  prob:  tensor([2.9734e-06])\n",
      "num:  tensor(1.)  log prob:  tensor([-8.2258])  prob:  tensor([0.0003])\n",
      "num:  tensor(1.5000)  log prob:  tensor([-4.7258])  prob:  tensor([0.0089])\n",
      "num:  tensor(2.)  log prob:  tensor([-2.2258])  prob:  tensor([0.1080])\n",
      "num:  tensor(2.5000)  log prob:  tensor([-0.7258])  prob:  tensor([0.4839])\n",
      "num:  tensor(3.)  log prob:  tensor([-0.2258])  prob:  tensor([0.7979])\n",
      "num:  tensor(3.5000)  log prob:  tensor([-0.7258])  prob:  tensor([0.4839])\n",
      "num:  tensor(4.)  log prob:  tensor([-2.2258])  prob:  tensor([0.1080])\n",
      "num:  tensor(4.5000)  log prob:  tensor([-4.7258])  prob:  tensor([0.0089])\n",
      "num:  tensor(5.)  log prob:  tensor([-8.2258])  prob:  tensor([0.0003])\n",
      "num:  tensor(5.5000)  log prob:  tensor([-12.7258])  prob:  tensor([2.9734e-06])\n"
     ]
    }
   ],
   "source": [
    "import torch\r\n",
    "import torch.nn\r\n",
    "import numpy as np \r\n",
    "from torch.distributions import Normal\r\n",
    "\r\n",
    "mean = torch.tensor([3.0])\r\n",
    "\r\n",
    "dist = Normal(mean,0.5)\r\n",
    "print (dist.sample())\r\n",
    "print (dist.log_prob(mean))\r\n",
    "print (np.exp(dist.log_prob(mean)))\r\n",
    "\r\n",
    "for x in torch.arange(0.0,6.0,step=0.5):\r\n",
    "    print(\"num: \", x, \" log prob: \", dist.log_prob(x), \" prob: \", np.exp(dist.log_prob(x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('drlnd': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9c18381fae07a4485791b53c4e8530c53984a1ff3ee4f71db22e62479b500740"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}